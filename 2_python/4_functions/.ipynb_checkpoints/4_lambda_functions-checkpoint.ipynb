{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Execution Time of `map`, `filter`, and Conventional For-Loops\n",
    "\n",
    "In AI and data processing, efficiency is crucial. Let's compare the execution times of `map`, `filter`, and conventional for-loops to understand the performance benefits of using higher-order functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Sample data\n",
    "numbers = list(range(1, 1000000))\n",
    "threshold = 500000\n",
    "\n",
    "# Conventional for-loop for map equivalent (square of each number)\n",
    "start_time = time.time()\n",
    "squares_conventional = []\n",
    "for num in numbers:\n",
    "    squares_conventional.append(num ** 2)\n",
    "end_time = time.time()\n",
    "conventional_map_time = end_time - start_time\n",
    "\n",
    "# Using map\n",
    "start_time = time.time()\n",
    "squares_map = #TODO \n",
    "end_time = time.time()\n",
    "map_time = end_time - start_time\n",
    "\n",
    "# Conventional for-loop for filter equivalent (numbers greater than threshold)\n",
    "start_time = time.time()\n",
    "filtered_conventional = []\n",
    "for num in numbers:\n",
    "    if num > threshold:\n",
    "        filtered_conventional.append(num)\n",
    "end_time = time.time()\n",
    "conventional_filter_time = end_time - start_time\n",
    "\n",
    "# Using filter\n",
    "start_time = time.time()\n",
    "filtered_filter = #TODO \n",
    "end_time = time.time()\n",
    "filter_time = end_time - start_time\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Conventional for-loop (map equivalent) took: {conventional_map_time:.6f} seconds\")\n",
    "print(f\"Map function took: {map_time:.6f} seconds\")\n",
    "print(f\"Conventional for-loop (filter equivalent) took: {conventional_filter_time:.6f} seconds\")\n",
    "print(f\"Filter function took: {filter_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Lambda Functions, Map, and Filter\n",
    "\n",
    "**Lambda Functions**: Lambda functions are small, anonymous functions defined using the `lambda` keyword. They are often used for short, simple operations that are not reused elsewhere. A lambda function can take any number of arguments but only has one expression.\n",
    "\n",
    "**Map Function**: The `map()` function applies a given function to all items in an input list (or any other iterable) and returns an iterator with the results. This is particularly useful for transforming data in a concise and readable manner.\n",
    "\n",
    "**Filter Function**: The `filter()` function constructs an iterator from elements of an iterable for which a function returns true. It is commonly used to extract items that meet certain criteria from a dataset.\n",
    "\n",
    "Let's explore these concepts through practical exercises related to managing large datasets in AI projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Normalizing Dataset Sizes with Lambda and Map\n",
    "#### Scenario:\n",
    "You are analyzing datasets of various sizes for an AI project and need to normalize the sizes of each dataset. Normalization ensures that all features contribute equally to the model, which is a crucial preprocessing step in many AI applications.\n",
    "\n",
    "#### Task:\n",
    "Normalize the sizes of datasets using a lambda function within the `map()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\n",
    "    [34, 63, 88, 71, 29],\n",
    "    [90, 78, 51, 27, 45],\n",
    "    [63, 37, 85, 46, 22],\n",
    "    [51, 22, 34, 11, 18]\n",
    "]\n",
    "\n",
    "# Use a lambda function within map to normalize the datasets\n",
    "normalized_data = None #TODO \n",
    "\n",
    "normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed Exercise 2: Filtering Datasets by Variance with Lambda and Filter\n",
    "#### Scenario:\n",
    "You need to filter datasets that have a variance above a specified threshold. Variance is a measure of the dispersion of data points and helps in identifying datasets with significant variability, which can be crucial for certain AI applications.\n",
    "\n",
    "#### Task:\n",
    "Filter datasets that have a variance above a specified threshold using a lambda function within the `filter()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    [34, 63, 88, 71, 29],\n",
    "    [90, 78, 51, 27, 45],\n",
    "    [63, 37, 85, 46, 22],\n",
    "    [51, 22, 34, 11, 18]\n",
    "]\n",
    "\n",
    "# Calculate variance for each dataset\n",
    "def variance(num_list):\n",
    "    mean_val = sum(num_list) / len(num_list)\n",
    "    return sum((x - mean_val) ** 2 for x in num_list) / len(num_list)\n",
    "\n",
    "# Filter datasets with variance above a threshold using a lambda function\n",
    "threshold = 400\n",
    "filtered_datasets = None #TODO \n",
    "\n",
    "filtered_datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
